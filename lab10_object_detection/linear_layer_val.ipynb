{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.1. Linear layer validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Domrachev Ivan, B20-Ro-01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to consider the problems, that previous implementation of layers might have had. \n",
    "\n",
    "It strictly shows, that all errors are *negligble* compared to model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_from_scratch.neurons import Linear, Convolution\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=(10, 2)\n",
    "output_dim=(10, 5)\n",
    "linear = Linear(input_dim, output_dim)\n",
    "\n",
    "# Random input values (x itself, and assumed partial derivative)\n",
    "x_input = np.random.rand(*input_dim)\n",
    "dL_dy = np.random.rand(*output_dim)\n",
    "\n",
    "# Forward call\n",
    "y_value = linear.forward(x_input)\n",
    "\n",
    "# Backpropogation\n",
    "dL_dx = linear.backward(dL_dy)\n",
    "dL_dw = linear._W_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate the results compared to tensorflow's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_batched = tf.constant(\n",
    "    x_input,\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "weights_reshaped = tf.constant(\n",
    "    linear.W[1:, :],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "bias_reshaped = tf.constant(\n",
    "    linear.W[0, :]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 2]), TensorShape([2, 5]), TensorShape([5]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_batched.shape, weights_reshaped.shape, bias_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_keras = layers.Dense(\n",
    "    5,\n",
    "    input_shape=(2,),\n",
    "    use_bias=True,\n",
    "    kernel_initializer=tf.keras.initializers.Constant(weights_reshaped),\n",
    "    bias_initializer=tf.keras.initializers.Constant(bias_reshaped)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x_input_batched)  # Watch the input tensor for gradient computation\n",
    "    conv_output = conv_keras(x_input_batched)\n",
    "\n",
    "conv_output_np = conv_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_output_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check that layer output is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(conv_output_np - y_value) < 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05123331\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(conv_output_np).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check that backpropogation for both input and weights is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dy_keras = tf.constant(dL_dy, dtype=tf.float32)\n",
    "\n",
    "dL_dx_keras = tape.gradient(\n",
    "    conv_output, x_input_batched, output_gradients=dL_dy_keras\n",
    ")\n",
    "dL_dw_keras = tape.gradient(\n",
    "    conv_output, conv_keras.trainable_variables, output_gradients=dL_dy_keras\n",
    ")\n",
    "\n",
    "dL_dx_keras_np = dL_dx_keras.numpy()\n",
    "dL_dw_keras_np = dL_dw_keras[0].numpy()\n",
    "dL_dbias_keras_np = dL_dw_keras[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03389214,  0.00468405],\n",
       "       [-0.06382886,  0.03250728],\n",
       "       [-0.06522863,  0.03782374],\n",
       "       [-0.13631496, -0.02891219],\n",
       "       [-0.14101057,  0.05950642],\n",
       "       [-0.10216872, -0.00614368],\n",
       "       [-0.0583231 ,  0.01871667],\n",
       "       [-0.052155  ,  0.0306218 ],\n",
       "       [-0.14564934, -0.01086044],\n",
       "       [-0.17198128,  0.03301783]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dx_keras_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03389214,  0.00468405],\n",
       "       [-0.06382886,  0.03250728],\n",
       "       [-0.06522863,  0.03782374],\n",
       "       [-0.13631496, -0.02891219],\n",
       "       [-0.14101057,  0.05950642],\n",
       "       [-0.10216872, -0.00614368],\n",
       "       [-0.0583231 ,  0.01871667],\n",
       "       [-0.052155  ,  0.0306218 ],\n",
       "       [-0.14564934, -0.01086043],\n",
       "       [-0.17198129,  0.03301783]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(dL_dx_keras_np - dL_dx) < 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.061667334"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(dL_dx_keras_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.411161 , 1.7951473, 2.291652 , 1.8384316, 1.2848475],\n",
       "       [1.6441565, 1.8421172, 2.079435 , 1.7833571, 1.8817294]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dw_keras_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.41116096, 1.79514724, 2.29165201, 1.83843166, 1.28484743],\n",
       "       [1.64415653, 1.84211717, 2.07943507, 1.78335713, 1.8817294 ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dw[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(dL_dw_keras_np - dL_dw[1:]) < 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.785203460316635"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(dL_dw[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(dL_dbias_keras_np - dL_dw[0]) < 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.892108001734596"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(dL_dw[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layer was extended to support batches inputs and optional bias input\n",
    "> Note: the solution is far from being generalized, f.e. it lacks padding, stride settings, as well as support of batches of the pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (10, 3, 7, 5)\n",
    "kernel_size = 2\n",
    "output_layers = 20\n",
    "conv = Convolution(input_dim, kernel_size, output_layers=output_layers, use_bias=False)\n",
    "output_dim = conv._output_dim\n",
    "\n",
    "# Random input values (x itself, and assumed partial derivative)\n",
    "x_input = np.random.random(input_dim).astype(dtype=np.float32)\n",
    "dL_dy = np.random.random(output_dim).astype(dtype=np.float32)\n",
    "\n",
    "output = conv.forward(x_input)\n",
    "dL_dx = conv.backward(dL_dy)\n",
    "dL_dw = conv._W_pd\n",
    "# bias = conv._B\n",
    "# dL_db = conv._B_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, m, n, p, q = input_dim[0], input_dim[2], input_dim[3], kernel_size, kernel_size\n",
    "assert all(\n",
    "    np.allclose(\n",
    "        output[i][kern][j][k], (x_input[i, :, j:j+p, k:k+q] * conv._W[kern]).sum()\n",
    "    ) \n",
    "    for i in range(b) \n",
    "    for j in range(m-p+1) \n",
    "    for k in range(n-q+1)\n",
    "    for kern in range(output_layers)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's compare its performance with tensorflow implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input_batched = tf.constant(\n",
    "    np.moveaxis(\n",
    "        x_input,\n",
    "        1, -1\n",
    "    ), \n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "weights_reshaped = tf.constant(\n",
    "    conv.W.transpose(2, 3, 1, 0),   \n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_keras = layers.Conv2D(\n",
    "    20, 2,\n",
    "    input_shape=x_input_batched.shape[1:],\n",
    "    use_bias=False,\n",
    "    kernel_initializer=tf.keras.initializers.Constant(weights_reshaped),\n",
    "    data_format='channels_last'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x_input_batched)  # Watch the input tensor for gradient computation\n",
    "    conv_output = conv_keras(x_input_batched)\n",
    "\n",
    "conv_output_np = conv_output.numpy()\n",
    "conv_output_np = np.moveaxis(conv_output_np, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check that layer output is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(conv_output_np - output)< 1e-7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33199567"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check that backpropogation for both input and weights is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dy_keras = tf.constant(np.moveaxis(dL_dy, 1, -1), dtype=tf.float32)\n",
    "\n",
    "dL_dx_keras = tape.gradient(\n",
    "    conv_output, x_input_batched, output_gradients=dL_dy_keras\n",
    ")\n",
    "dL_dw_keras = tape.gradient(\n",
    "    conv_output, conv_keras.trainable_variables, output_gradients=dL_dy_keras\n",
    ")\n",
    "\n",
    "dL_dx_keras_np = np.moveaxis(dL_dx_keras.numpy().squeeze(), -1, 1)\n",
    "dL_dw_keras_np = np.moveaxis(dL_dw_keras[0].numpy().squeeze(), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 7, 5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dx_keras_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 7, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(dL_dx_keras_np - dL_dx) < 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23194458"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(dL_dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(dL_dw_keras_np - np.moveaxis(dL_dw, 1, -1))< 1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.58165"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(dL_dw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
