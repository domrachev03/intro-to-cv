{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8, part 2: Convolutional Neural Network sample\n",
    "by Domrachev Ivan, B20-Ro-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from nn_from_scratch.optimizers import GradientDescent\n",
    "from nn_from_scratch.examples.simple_nn import NeuralNetwork\n",
    "from nn_from_scratch.nodes import ReLU, SoftMaxLoss, Vectorization\n",
    "from nn_from_scratch.neurons import Linear, Convolution\n",
    "from nn_from_scratch.interfaces import Neuron\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as t_layers\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. One layer NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, everything is ready to create a Convolutional Neural Network!\n",
    "\n",
    "Conviniently, the framework from the simple Neural Network is suitable for the CNN as well, so let's utilize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "# CNN are slow...\n",
    "train_X, train_y = train_X[:1000], train_y[:1000]\n",
    "# Shuffle\n",
    "\n",
    "p = np.random.permutation(len(train_X))\n",
    "train_X, train_y = train_X[p], train_y[p]\n",
    "\n",
    "n_input, n_output, batch_size, n_channels = 28**2, 10, 50, 1\n",
    "assert train_X.shape[0] % batch_size == 0\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0] // batch_size, batch_size, n_channels, 28, 28)\n",
    "train_y_ohe = np.zeros((len(train_y), n_output))\n",
    "train_y_ohe[np.arange(len(train_y)), train_y] = 1\n",
    "train_y_ohe = train_y_ohe.reshape((train_y.shape[0] // batch_size, batch_size, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values preferably should belong to $[0; 1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X / 255\n",
    "test_X = test_X / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:26<00:49,  3.81s/it, loss=2.34]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m SoftMaxLoss((batch_size, n_output))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m network \u001b[39m=\u001b[39m NeuralNetwork(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     n_input\u001b[39m=\u001b[39mn_input, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     n_output\u001b[39m=\u001b[39mn_output, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39mloss_fn\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m network\u001b[39m.\u001b[39;49mfit(train_X, train_y_ohe, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/nn_from_scratch/nn_from_scratch/examples/simple_nn.py:54\u001b[0m, in \u001b[0;36mNeuralNetwork.fit\u001b[0;34m(self, X, y, n_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m partial_derivative \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m     53\u001b[0m     \u001b[39m# print(partial_derivative.shape)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     partial_derivative \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward(partial_derivative)\n\u001b[1;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, Neuron):\n\u001b[1;32m     56\u001b[0m         layer\u001b[39m.\u001b[39moptimize_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opt)\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/nn_from_scratch/nn_from_scratch/neurons.py:358\u001b[0m, in \u001b[0;36mConvolution.backward\u001b[0;34m(self, input_pd, reset_after)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size):\n\u001b[1;32m    357\u001b[0m         backprop_pd[batch_idx] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[0;32m--> 358\u001b[0m             [\n\u001b[1;32m    359\u001b[0m                 np\u001b[39m.\u001b[39;49mconcatenate(\n\u001b[1;32m    360\u001b[0m                     [\n\u001b[1;32m    361\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convolve(\n\u001b[1;32m    362\u001b[0m                             input_pd[batch_idx, conv_layer],\n\u001b[1;32m    363\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_W[conv_layer, depth, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    364\u001b[0m                             add_padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    365\u001b[0m                         )\n\u001b[1;32m    366\u001b[0m                         \u001b[39mfor\u001b[39;49;00m depth \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_dim[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    367\u001b[0m                     ], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m    368\u001b[0m                 )\n\u001b[1;32m    369\u001b[0m                 \u001b[39mfor\u001b[39;49;00m conv_layer \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_layers)\n\u001b[1;32m    370\u001b[0m             ], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    371\u001b[0m         )[:, \u001b[39m0\u001b[39m, :, :]\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m reset_after:\n\u001b[1;32m    373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/nn_from_scratch/nn_from_scratch/neurons.py:360\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size):\n\u001b[1;32m    357\u001b[0m         backprop_pd[batch_idx] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[1;32m    358\u001b[0m             [\n\u001b[1;32m    359\u001b[0m                 np\u001b[39m.\u001b[39mconcatenate(\n\u001b[0;32m--> 360\u001b[0m                     [\n\u001b[1;32m    361\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convolve(\n\u001b[1;32m    362\u001b[0m                             input_pd[batch_idx, conv_layer],\n\u001b[1;32m    363\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_W[conv_layer, depth, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    364\u001b[0m                             add_padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    365\u001b[0m                         )\n\u001b[1;32m    366\u001b[0m                         \u001b[39mfor\u001b[39;49;00m depth \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_dim[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    367\u001b[0m                     ], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    368\u001b[0m                 )\n\u001b[1;32m    369\u001b[0m                 \u001b[39mfor\u001b[39;00m conv_layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_layers)\n\u001b[1;32m    370\u001b[0m             ], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    371\u001b[0m         )[:, \u001b[39m0\u001b[39m, :, :]\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m reset_after:\n\u001b[1;32m    373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/nn_from_scratch/nn_from_scratch/neurons.py:361\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_size):\n\u001b[1;32m    357\u001b[0m         backprop_pd[batch_idx] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[1;32m    358\u001b[0m             [\n\u001b[1;32m    359\u001b[0m                 np\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m    360\u001b[0m                     [\n\u001b[0;32m--> 361\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convolve(\n\u001b[1;32m    362\u001b[0m                             input_pd[batch_idx, conv_layer],\n\u001b[1;32m    363\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_W[conv_layer, depth, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    364\u001b[0m                             add_padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    365\u001b[0m                         )\n\u001b[1;32m    366\u001b[0m                         \u001b[39mfor\u001b[39;00m depth \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dim[\u001b[39m1\u001b[39m])\n\u001b[1;32m    367\u001b[0m                     ], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    368\u001b[0m                 )\n\u001b[1;32m    369\u001b[0m                 \u001b[39mfor\u001b[39;00m conv_layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_layers)\n\u001b[1;32m    370\u001b[0m             ], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    371\u001b[0m         )[:, \u001b[39m0\u001b[39m, :, :]\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m reset_after:\n\u001b[1;32m    373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/nn_from_scratch/nn_from_scratch/neurons.py:262\u001b[0m, in \u001b[0;36mConvolution._convolve\u001b[0;34m(self, T, W, add_padding)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(output_shape[\u001b[39m2\u001b[39m]):\n\u001b[1;32m    261\u001b[0m             \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(output_shape[\u001b[39m3\u001b[39m]):\n\u001b[0;32m--> 262\u001b[0m                 res[bch][kern][j][k] \u001b[39m=\u001b[39m (T[bch, :, j:j\u001b[39m+\u001b[39;49mW\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m], k:k\u001b[39m+\u001b[39;49mW\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m]] \u001b[39m*\u001b[39;49m W[kern])\u001b[39m.\u001b[39;49msum()\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gds = GradientDescent(lr=1e8)\n",
    "layers = [\n",
    "    Convolution(\n",
    "        (batch_size, n_channels, 28, 28), \n",
    "        kernel_size=3, \n",
    "        output_layers=4,\n",
    "        use_bias=False\n",
    "    ),\n",
    "    ReLU((batch_size, 4, 26, 26)),\n",
    "    Convolution(\n",
    "        (batch_size, 4, 26, 26), \n",
    "        kernel_size=7,\n",
    "        output_layers=2,\n",
    "        use_bias=False\n",
    "    ),\n",
    "    ReLU((batch_size, 2, 20, 20)),\n",
    "    Vectorization((batch_size, 2, 20, 20)),\n",
    "    Linear((batch_size, 800), (batch_size, n_output))\n",
    "]\n",
    "loss_fn = SoftMaxLoss((batch_size, n_output))\n",
    "network = NeuralNetwork(\n",
    "    n_input=n_input, \n",
    "    n_output=n_output, \n",
    "    batch_size=batch_size, \n",
    "    optimizer=gds,\n",
    "    layers=layers,  \n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "network.fit(train_X, train_y_ohe, n_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, loss is decreasing very slowly. Strange, let's check the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(test_X: np.array, test_y: np.array, model) -> float:\n",
    "    correct_predictions = 0\n",
    "    total = 0\n",
    "\n",
    "    for test_inputs, test_labels in zip(test_X, test_y):\n",
    "        predicts = model.predict(test_inputs)\n",
    "        pred_class = np.argmax(predicts, axis=1)\n",
    "\n",
    "        correct_predictions += (pred_class == test_labels).sum()\n",
    "        total += len(test_labels)\n",
    "\n",
    "    return correct_predictions / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1053\n"
     ]
    }
   ],
   "source": [
    "test_X_batches = test_X.reshape((test_X.shape[0] // batch_size, batch_size, 28, 28))\n",
    "test_y_batches = test_y.reshape((test_y.shape[0] // batch_size, batch_size,))\n",
    "\n",
    "acc = compute_accuracy(test_X_batches, test_y_batches, network)\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, they are random... Maybe the model itself is invalid, let's train tensorflow analogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Learning TensorFlow network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is straight-forward, would not explain much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = np.expand_dims(train_X / 255, axis=-1)\n",
    "test_X = np.expand_dims(test_X / 255, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         36        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 26, 26, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 2)         392       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 20, 20, 2)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8438 (32.96 KB)\n",
      "Trainable params: 8438 (32.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 21:15:36.409917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-13 21:15:36.410788: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "tf_layers = [\n",
    "    t_layers.Conv2D(\n",
    "        4, 3,\n",
    "        input_shape=train_X.shape[1:],\n",
    "        use_bias=False,\n",
    "    ),\n",
    "    t_layers.ReLU(),\n",
    "    t_layers.Conv2D(\n",
    "        2, 7,\n",
    "        use_bias=False,\n",
    "    ),\n",
    "    t_layers.ReLU(),\n",
    "    t_layers.Flatten(),\n",
    "    t_layers.Dense(\n",
    "        10,\n",
    "        use_bias=True,\n",
    "    )\n",
    "]\n",
    "model = tf.keras.models.Sequential()\n",
    "for l in tf_layers:\n",
    "    model.add(l)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 21:15:36.700702: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1875 [======================>.......] - ETA: 4s - loss: 0.6234 - accuracy: 0.7996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msgd\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_X, train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dom_iva/Programms/intro_to_cv/lab8_CNN/cnn.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(test_X, test_y))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=5, \n",
    "                    validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy there is not random, and the network performs great. Maybe the weights are different?.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Comparison with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should compare:\n",
    "1. Outputs of the model (given the same initial weights and the same input)\n",
    "2. Partial derivative of loss w.r.t. input. If they are close enough, then all the inner states are similar as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pic, example_label = train_X[0], train_y_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = example_pic.copy()\n",
    "for layer in layers:\n",
    "    state = layer.forward(state)\n",
    "\n",
    "loss = loss_fn.forward(state, example_label)\n",
    "dL_dy = loss_fn.backward()\n",
    "partial_derivative = dL_dy\n",
    "dL_dx = []\n",
    "dL_dw = []\n",
    "\n",
    "for layer in layers[::-1]:\n",
    "    partial_derivative = layer.backward(partial_derivative)\n",
    "    dL_dx.append(partial_derivative)\n",
    "\n",
    "    if isinstance(layer, Neuron):\n",
    "        dL_dw.append(layer._W_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:16:17.564457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-07 14:16:17.565690: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "example_pic_tf = tf.constant(\n",
    "    np.moveaxis(\n",
    "        example_pic,\n",
    "        1, -1\n",
    "    ), \n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "weights_tf = [\n",
    "    tf.constant(\n",
    "        np.moveaxis(\n",
    "            l.W,\n",
    "            0, -1\n",
    "        ).astype(np.float32)\n",
    "    )\n",
    "    for l in [layers[0], layers[2]]\n",
    "]\n",
    "weights_tf.extend([\n",
    "    tf.constant(\n",
    "        np.moveaxis(\n",
    "            layers[5].W[1:, :],\n",
    "            0, -1\n",
    "        ).astype(np.float32)\n",
    "    ),\n",
    "    tf.constant(\n",
    "        np.moveaxis(\n",
    "            layers[5].W[0, :],\n",
    "            0, -1\n",
    "        ).astype(np.float32)\n",
    "    ),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 28, 28, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pic_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         36        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 26, 26, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 2)         392       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 20, 20, 2)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8438 (32.96 KB)\n",
      "Trainable params: 8438 (32.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_layers = [\n",
    "    t_layers.Conv2D(\n",
    "        4, 3,\n",
    "        input_shape=example_pic_tf.shape[1:],\n",
    "        use_bias=False,\n",
    "        kernel_initializer=tf.keras.initializers.Constant(weights_tf[0])\n",
    "    ),\n",
    "    t_layers.ReLU(),\n",
    "    t_layers.Conv2D(\n",
    "        2, 7,\n",
    "        use_bias=False,\n",
    "        kernel_initializer=tf.keras.initializers.Constant(weights_tf[1])\n",
    "    ),\n",
    "    t_layers.ReLU(),\n",
    "    t_layers.Flatten(),\n",
    "    t_layers.Dense(\n",
    "        10,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=tf.keras.initializers.Constant(weights_tf[2]),\n",
    "        bias_initializer=tf.keras.initializers.Constant(weights_tf[3])\n",
    "    )\n",
    "]\n",
    "model = tf.keras.models.Sequential()\n",
    "for l in tf_layers:\n",
    "    model.add(l)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(example_pic_tf)\n",
    "    conv_output = model(example_pic_tf)\n",
    "\n",
    "conv_output_np = conv_output.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The outputs are similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max((conv_output_np - state[0]) < 2e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dy_keras = tf.constant(np.moveaxis(dL_dy, 1, -1), dtype=tf.float32)\n",
    "\n",
    "dL_dx_keras = tape.gradient(conv_output, example_pic_tf, output_gradients=dL_dy_keras)\n",
    "\n",
    "dL_dw_keras = [\n",
    "    tape.gradient(conv_output, layer_i.trainable_variables)\n",
    "    for layer_i in [tf_layers[0], tf_layers[2], tf_layers[5]]\n",
    "]\n",
    "\n",
    "dL_dx_keras_np = np.moveaxis(dL_dx_keras.numpy(), -1, 1)\n",
    "dL_dw_keras_np = [dL_dw_keras_i[0].numpy() for dL_dw_keras_i in dL_dw_keras][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw[0] = dL_dw[0][1:, :]\n",
    "dL_dw[1] = dL_dw[1].T\n",
    "dL_dw[2] = dL_dw[2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 10)\n",
      "(7, 7, 4, 2)\n",
      "(3, 3, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "for a in dL_dw_keras_np:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The output of the backpropogation is similar (hence, all the inner states of back propogation are similar as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((dL_dx_keras_np - dL_dx[-1]) < 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have several ideas why results diverge and will try to fix them in future works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
