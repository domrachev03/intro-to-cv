{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2, Nearest Neighbour (NN)\n",
    "by Domrachev Ivan, B20-RO-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "from collections.abc import Iterable, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Finishing lab task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the task is to continue considering a toy example from the lab and test the second test data and consider another metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 0. 0. 1.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Generating train data\n",
    "train_data = np.array([\n",
    "    np.eye(4) + np.eye(4)[::-1],\n",
    "    np.ones((4,4))\n",
    "])\n",
    "train_data[1, 1:3, 1:3] = 0\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "\n",
    "train_labels = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1.],\n",
       "        [1., 1., 0., 1.]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating test data\n",
    "test_data = np.copy(train_data)\n",
    "test_data[0, ((1,2)), ((2,1)),] = 0\n",
    "test_data[1, ((1, 3)), ((3, 2)),] = 0\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(\n",
    "        train_ds: Iterable[np.array, np.array], \n",
    "        test_data: np.array, \n",
    "        dist_func: Callable[[np.array, np.array], np.array],\n",
    "        K: int = 1\n",
    ") -> int:\n",
    "    \"\"\"Predicts class of test_data given train_data\n",
    "    \n",
    "        Keyword arguments:\n",
    "        train_ds -- (train_data, train_labels), the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "        dist_func -- function to measure the distance\n",
    "        \n",
    "        Returns:\n",
    "        Class prediction, according to the train_labels\"\"\"\n",
    "    train_data, train_labels = train_ds\n",
    "    distance = dist_func(train_data, test_data)\n",
    "    \n",
    "    if K == 1:\n",
    "        return train_labels[distance.argmin()]\n",
    "    else:\n",
    "        # Get K indices of K least elements\n",
    "        closest_classes = train_labels[np.argpartition(-distance, K)[:K]]\n",
    "        # Return the most frequent inxed. If there are several,\n",
    "        # return the first one (a.k.a. the smallest)\n",
    "        return train_labels[\n",
    "            closest_classes[closest_classes.argmax()]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_dist(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures distance as absolute distance between entries \n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Absolute distance for each train_data entry\"\"\"\n",
    "    return np.abs(\n",
    "        train_data - test_data\n",
    "    ).sum(\n",
    "        axis = tuple(\n",
    "            i for i in range(1, train_data.ndim)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def mult_dist(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures distance as matrix multiplication \n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Multiplication distance for each train_data entry\"\"\"\n",
    "    # Apparently, one single multiplication is longer to compute\n",
    "    # than many small ones (this becomes important for CIFAR10)\n",
    "    sum = 0\n",
    "    for train_entry in train_data:\n",
    "        sum += (train_entry.T @ test_data.T).sum()\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['circle', 'cross'], ['circle', 'circle'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions for the data\n",
    "pred1 = [\n",
    "    KNN(\n",
    "        (train_data, train_labels), \n",
    "        test_data_i, \n",
    "        abs_dist\n",
    "    ) for test_data_i in test_data\n",
    "]\n",
    "pred2 = [\n",
    "    KNN(\n",
    "        (train_data, train_labels), \n",
    "        test_data_i, \n",
    "        mult_dist\n",
    "    ) for test_data_i in test_data\n",
    "]\n",
    "\n",
    "pred1_labeled = [\"cross\" if pred1_i else \"circle\" for pred1_i in pred1]\n",
    "pred2_labeled = [\"cross\" if pred2_i else \"circle\" for pred2_i in pred2]\n",
    "\n",
    "pred1_labeled, pred2_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, one could say that absolute distance metric (`abs_dist`) works better for this task, because it shows better performance for the second test entry. It is correct for the first metric, but incorrect for the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Testing 2 KNN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Implementing 2-KNN manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, one need to load CIFAR10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # This normalization values are precomputed for CIFAR-10 dataset,\n",
    "    # refer to: https://github.com/kuangliu/pytorch-cifar/issues/19\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "# Train\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Test \n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# List of classes\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the trainset and testset to the numpy arrays and test it's performance with our CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np = trainset.data\n",
    "train_labels_np = np.array(trainset.targets)\n",
    "test_data_np = testset.data[:100]\n",
    "test_labels_np = np.array(testset.targets)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54915f1f70b54a079ae863a7b614391c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test absolute value:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~16 seconds\n",
    "pred1 = []\n",
    "test_loop_1 = tqdm(enumerate(test_data_np, 0), total=len(test_data_np), desc=\"Test absolute value\")\n",
    "for i, input in test_loop_1:\n",
    "    pred1.append(\n",
    "        KNN(\n",
    "            (train_data_np, train_labels_np), \n",
    "            input, \n",
    "            abs_dist\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e79758801a41568f3e95e9bff52663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~7.5 minutes\n",
    "pred2 = []\n",
    "test_loop = tqdm(enumerate(test_data_np, 0), total=len(test_data_np), desc=\"Test multiplication\")\n",
    "for i, input in test_loop:\n",
    "    pred2.append(\n",
    "        KNN(\n",
    "            (train_data_np, train_labels_np), \n",
    "            input, \n",
    "            mult_dist\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.array(pred1)\n",
    "pred2 = np.array(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of absolute distance: 0.07\n",
      "Accuracy of product distance: 0.07\n"
     ]
    }
   ],
   "source": [
    "acc1 = (pred1 == test_labels_np).sum() / len(pred1)\n",
    "acc2 = (pred2 == test_labels_np).sum() / len(pred2)\n",
    "\n",
    "print(f\"Accuracy of absolute distance: {acc1}\")\n",
    "print(f\"Accuracy of product distance: {acc2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one could see, the accuracy is quite low without encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing encoded data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a prepared encoder, I've decided to borrow a RESNET model, trained on CIFAR-10 from [here](https://github.com/huyvnphan/PyTorch_CIFAR10/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git submodule add https://github.com/huyvnphan/PyTorch_CIFAR10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyTorch_CIFAR10.cifar10_models.resnet import resnet50\n",
    "\n",
    "model = resnet50()\n",
    "ckpt = torch.load(\"data/resnet50.pt\")\n",
    "model.load_state_dict(ckpt)\n",
    "encoding_model = torch.nn.Sequential(*(list(model.children())[:-1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80a788ee7114cbebed98e011e853fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train encoding:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     test_loop \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(trainloader, \u001b[39m0\u001b[39m), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(trainloader), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain encoding\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i, inputs \u001b[39min\u001b[39;00m test_loop:\n\u001b[0;32m----> 6\u001b[0m         trainset_encoded\u001b[39m.\u001b[39mappend(encoding_model(inputs[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m      7\u001b[0m trainset_encoded[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/lab2_nearest_neighbour/PyTorch_CIFAR10/cifar10_models/resnet.py:121\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m    119\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m--> 121\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(out)\n\u001b[1;32m    122\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(out)\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainset_encoded = []\n",
    "with torch.no_grad():\n",
    "    encoding_model.eval()  # evaluation mode\n",
    "    test_loop = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc=\"Train encoding\")\n",
    "    for i, inputs in test_loop:\n",
    "        trainset_encoded.append(encoding_model(inputs[0]))\n",
    "trainset_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55a348a508c446baa5b04fb310846ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test encoding:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 0.5189,  0.5347,  0.6299,  ...,  0.1856,  0.0110, -0.1477],\n",
      "          [ 0.4236,  0.4078,  0.5347,  ...,  0.1697, -0.0049, -0.1001],\n",
      "          [ 0.4078,  0.4078,  0.5189,  ...,  0.2173,  0.0745, -0.0842],\n",
      "          ...,\n",
      "          [-0.9095, -1.3221, -1.4967,  ..., -1.3856, -1.7824, -1.3539],\n",
      "          [-1.0206, -1.2110, -1.4332,  ..., -1.5760, -1.5284, -1.6713],\n",
      "          [-1.1317, -1.0999, -1.2745,  ..., -1.6078, -1.4491, -1.6554]],\n",
      "\n",
      "         [[-0.1765, -0.1926, -0.1121,  ..., -0.4503, -0.5147, -0.6114],\n",
      "          [-0.1765, -0.2087, -0.1443,  ..., -0.4503, -0.5147, -0.5630],\n",
      "          [-0.2087, -0.2248, -0.1926,  ..., -0.4020, -0.4503, -0.5469],\n",
      "          ...,\n",
      "          [ 0.0167, -0.3698, -0.5630,  ..., -0.4181, -0.9496, -0.6114],\n",
      "          [-0.1121, -0.3376, -0.6114,  ..., -0.6597, -0.6597, -0.9496],\n",
      "          [-0.2571, -0.2893, -0.5469,  ..., -0.7402, -0.6275, -0.9013]],\n",
      "\n",
      "         [[-0.9723, -1.0022, -0.9423,  ..., -1.1671, -1.1671, -1.2121],\n",
      "          [-0.9423, -1.1072, -1.0322,  ..., -1.2421, -1.2271, -1.1971],\n",
      "          [-1.0022, -1.2121, -1.1671,  ..., -1.1971, -1.1971, -1.2121],\n",
      "          ...,\n",
      "          [ 0.9466,  0.5118,  0.3469,  ...,  0.4818, -0.0878,  0.1970],\n",
      "          [ 0.8116,  0.5118,  0.2720,  ...,  0.2420,  0.1820, -0.1028],\n",
      "          [ 0.6917,  0.5268,  0.2720,  ...,  0.1520,  0.2270, -0.0578]]]]), tensor([3])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i, inputs \u001b[39min\u001b[39;00m test_loop:\n\u001b[1;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(inputs)\n\u001b[0;32m----> 7\u001b[0m         testset_encoded\u001b[39m.\u001b[39mappend(model(inputs))\n\u001b[1;32m      8\u001b[0m testset_encoded[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programms/intro_to_cv/lab2_nearest_neighbour/PyTorch_CIFAR10/cifar10_models/resnet.py:245\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 245\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    246\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    247\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_courses/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (list, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list of [Tensor, Tensor]!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "testset_encoded = []\n",
    "with torch.no_grad():\n",
    "    encoding_model.eval()  # evaluation mode\n",
    "    test_loop = tqdm(enumerate(testloader, 0), total=len(testloader), desc=\"Test encoding\")\n",
    "    for i, inputs in test_loop:\n",
    "        testset_encoded.append(encoding_model(inputs[0]))\n",
    "testset_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_encoded = [entry.numpy() for entry in trainset_encoded]\n",
    "testset_encoded = [entry.numpy() for entry in testset_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures cosine similarity between inputs\n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Cosine similarity for each train_data entry\"\"\"\n",
    "       \n",
    "    return train_data.dot(test_data) / (train_data.norm()*test_data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_encoded = []\n",
    "test_loop = tqdm(enumerate(test_data_np, 0), total=len(test_data_np), desc=\"Test\")\n",
    "for i, input in test_loop:\n",
    "    pred2.append(\n",
    "        KNN(\n",
    "            (trainset_encoded, testset_encoded), \n",
    "            input, \n",
    "            cosine_similarity\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
