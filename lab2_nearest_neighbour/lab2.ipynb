{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2, Nearest Neighbour (NN)\n",
    "by Domrachev Ivan, B20-RO-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "from collections.abc import Iterable, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Finishing lab task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the task is to continue considering a toy example from the lab and test the second test data and consider another metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 0. 0. 1.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Generating train data\n",
    "train_data = np.array([\n",
    "    np.eye(4) + np.eye(4)[::-1],\n",
    "    np.ones((4,4))\n",
    "])\n",
    "train_data[1, 1:3, 1:3] = 0\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "\n",
    "train_labels = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1.],\n",
       "        [1., 1., 0., 1.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating test data\n",
    "test_data = np.copy(train_data)\n",
    "test_data[0, ((1,2)), ((2,1)),] = 0\n",
    "test_data[1, ((1, 3)), ((3, 2)),] = 0\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(\n",
    "        train_ds: Iterable[np.array, np.array], \n",
    "        test_data: np.array, \n",
    "        dist_func: Callable[[np.array, np.array], np.array],\n",
    "        K: int = 1\n",
    ") -> int:\n",
    "    \"\"\"Predicts class of test_data given train_data\n",
    "    \n",
    "        Keyword arguments:\n",
    "        train_ds -- (train_data, train_labels), the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "        dist_func -- function to measure the distance\n",
    "        \n",
    "        Returns:\n",
    "        Class prediction, according to the train_labels\"\"\"\n",
    "    train_data, train_labels = train_ds\n",
    "    distance = dist_func(train_data, test_data)\n",
    "    if K == 1:\n",
    "        return train_labels[distance.argmin()]\n",
    "    else:\n",
    "        # Get K indices of K least elements\n",
    "        closest_classes = train_labels[np.argpartition(-distance, K)[:K]]\n",
    "        # Return the most frequent inxed. If there are several,\n",
    "        # return the first one (a.k.a. the smallest)\n",
    "        return train_labels[\n",
    "            closest_classes[closest_classes.argmax()]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_dist(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures distance as absolute distance between entries \n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Absolute distance for each train_data entry\"\"\"\n",
    "    return np.abs(\n",
    "        train_data - test_data\n",
    "    ).sum(\n",
    "        axis = tuple(\n",
    "            i for i in range(1, train_data.ndim)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def mult_dist(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures distance as matrix multiplication \n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Multiplication distance for each train_data entry\"\"\"\n",
    "    # Apparently, one single multiplication is longer to compute\n",
    "    # than many small ones (this becomes important for CIFAR10)\n",
    "    sum = 0\n",
    "    for train_entry in train_data:\n",
    "        sum += (train_entry.T @ test_data.T).sum()\n",
    "    \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['circle', 'cross'], ['circle', 'circle'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions for the data\n",
    "pred1 = [\n",
    "    KNN(\n",
    "        (train_data, train_labels), \n",
    "        test_data_i, \n",
    "        abs_dist\n",
    "    ) for test_data_i in test_data\n",
    "]\n",
    "pred2 = [\n",
    "    KNN(\n",
    "        (train_data, train_labels), \n",
    "        test_data_i, \n",
    "        mult_dist\n",
    "    ) for test_data_i in test_data\n",
    "]\n",
    "\n",
    "pred1_labeled = [\"cross\" if pred1_i else \"circle\" for pred1_i in pred1]\n",
    "pred2_labeled = [\"cross\" if pred2_i else \"circle\" for pred2_i in pred2]\n",
    "\n",
    "pred1_labeled, pred2_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, one could say that absolute distance metric (`abs_dist`) works better for this task, because it shows better performance for the second test entry. It is correct for the first metric, but incorrect for the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Testing 2 KNN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Implementing 2-KNN manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, one need to load CIFAR10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # This normalization values are precomputed for CIFAR-10 dataset,\n",
    "    # refer to: https://github.com/kuangliu/pytorch-cifar/issues/19\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "# Train\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Test \n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# List of classes\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the trainset and testset to the numpy arrays and test it's performance with our CNN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np = trainset.data\n",
    "train_labels_np = np.array(trainset.targets)\n",
    "test_data_np = testset.data\n",
    "test_labels_np = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58f48993264c30b25a6be67da356e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test absolute value:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~16 seconds\n",
    "N_pred1 = 1000\n",
    "pred1 = np.zeros(N_pred1)\n",
    "test_loop_1 = tqdm(\n",
    "    enumerate(test_data_np[:N_pred1], 0), total=N_pred1, desc=\"Test absolute value\"\n",
    ")\n",
    "\n",
    "for i, input in test_loop_1:\n",
    "    pred1[i] = KNN (\n",
    "        (train_data_np, train_labels_np), \n",
    "        input, \n",
    "        abs_dist\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cee41c4b6c4c00877b889f230e43cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test multiplication:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ~7.5 minutes\n",
    "N_pred2 = 100\n",
    "pred2 = np.zeros(N_pred2)\n",
    "test_loop = tqdm(\n",
    "    enumerate(test_data_np[:N_pred2], 0), total=N_pred2, desc=\"Test multiplication\"\n",
    ")\n",
    "\n",
    "for i, input in test_loop:\n",
    "    pred2[i]= KNN (\n",
    "        (train_data_np, train_labels_np), \n",
    "        input, \n",
    "        mult_dist\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of absolute distance: 0.253\n",
      "Accuracy of product distance: 0.16\n"
     ]
    }
   ],
   "source": [
    "acc1 = (pred1 == test_labels_np[:N_pred1]).sum() / N_pred1\n",
    "acc2 = (pred2 == test_labels_np[:N_pred2]).sum() / N_pred2\n",
    "\n",
    "print(f\"Accuracy of absolute distance: {acc1}\")\n",
    "print(f\"Accuracy of product distance: {acc2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one could see, the accuracy is quite low without encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Testing encoded data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a prepared encoder, I've decided to borrow a RESNET model, trained on CIFAR-10 from [here](https://github.com/huyvnphan/PyTorch_CIFAR10/tree/master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git submodule add https://github.com/huyvnphan/PyTorch_CIFAR10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyTorch_CIFAR10.cifar10_models.resnet import resnet50\n",
    "\n",
    "model = resnet50()\n",
    "ckpt = torch.load(\"data/resnet50.pt\")\n",
    "model.load_state_dict(ckpt)\n",
    "encoding_model = torch.nn.Sequential(*(list(model.children())[:-1]));\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "# encoding_model = torch.nn.Sequential(*(list(model.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650decd3711345ac9d1d5f08bb4e6290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train encoding:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset_encoded = []\n",
    "with torch.no_grad():\n",
    "    encoding_model.eval()  # evaluation mode\n",
    "    test_loop = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc=\"Train encoding\")\n",
    "    for i, inputs in test_loop:\n",
    "        trainset_encoded.append(encoding_model(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4aa28660f74338a35e852803ff08b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test encoding:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testset_encoded = []\n",
    "with torch.no_grad():\n",
    "    encoding_model.eval()  # evaluation mode\n",
    "    test_loop = tqdm(enumerate(testloader, 0), total=len(testloader), desc=\"Test encoding\")\n",
    "    for i, inputs in test_loop:\n",
    "        testset_encoded.append(encoding_model(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 2048), (10000, 2048))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_encoded = np.array([entry.numpy() for entry in trainset_encoded]).reshape(50000, -1)\n",
    "testset_encoded = np.array([entry.numpy() for entry in testset_encoded]).reshape(10000, -1)\n",
    "\n",
    "trainset_encoded.shape, testset_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try to test the encoded values with previous metric -- absolute distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c935dad82214d958b5c097ba223189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test encoded values, absolute distance:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_pred_encoded = 1000\n",
    "pred_encoded = np.zeros(N_pred_encoded)\n",
    "test_loop = tqdm(\n",
    "    enumerate(testset_encoded[:N_pred_encoded], 0), total=N_pred_encoded, desc=\"Test encoded values, absolute distance\"\n",
    ")\n",
    "for i, input in test_loop:\n",
    "    pred_encoded[i]= KNN (\n",
    "        (trainset_encoded, train_labels_np), \n",
    "        input, \n",
    "        abs_dist\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of encoded values, absolute distance: 0.123\n"
     ]
    }
   ],
   "source": [
    "acc_encoded = (pred_encoded == test_labels_np[:N_pred_encoded]).sum() / N_pred_encoded\n",
    "print(f\"Accuracy of encoded values, absolute distance: {acc_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(train_data: np.array, test_data: np.array) -> np.array:\n",
    "    \"\"\" Measures cosine similarity between inputs\n",
    "        \n",
    "        Keyword arguments:\n",
    "        train_data -- the actual dataset\n",
    "        test_data -- the data to be tested\n",
    "            \n",
    "        Returns:\n",
    "        Cosine similarity for each train_data entry\"\"\"\n",
    "    \n",
    "    return train_data.dot(test_data) / (\n",
    "        np.linalg.norm(train_data) * np.linalg.norm(test_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c733f69d6684d55b0ac0a4e3e104e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test encoded values, cosine similarity:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_pred_encoded = 1000\n",
    "pred_encoded = np.zeros(N_pred_encoded)\n",
    "test_loop = tqdm(\n",
    "    enumerate(testset_encoded[:N_pred_encoded], 0), total=N_pred_encoded, desc=\"Test encoded values, cosine similarity\"\n",
    ")\n",
    "for i, input in test_loop:\n",
    "    pred_encoded[i]= KNN (\n",
    "        (trainset_encoded, train_labels_np), \n",
    "        input, \n",
    "        cosine_similarity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of encoded values, cosine similarity: 0.127\n"
     ]
    }
   ],
   "source": [
    "acc_encoded = (pred_encoded == test_labels_np[:N_pred_encoded]).sum() / N_pred_encoded\n",
    "print(f\"Accuracy of encoded values, cosine similarity: {acc_encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that the cosine similarity metric show worse result, little more accurate than random prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps one might take to improve the accuracy of the result:\n",
    "1. *Try another model*. I've considered two examples, but both of them failed to perform well. Hovewer, there exist some other options to test.\n",
    "2. *Remove some convolutional layers*. The KNN algorithm generally works poorly for sparse data. Hence, one could try to remove more sensors from the initial NN and get more meaningful and dence feature list. *I failed to try this because it broke my OS*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
